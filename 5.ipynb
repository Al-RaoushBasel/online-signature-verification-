{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "56df9507",
   "metadata": {},
   "source": [
    "# üîß Signature Verification ‚Äî Notebook #5 (Model Tuning & Stacking)\n",
    "This notebook explores advanced model improvements:\n",
    "- GridSearchCV tuning for XGBoost and MLP\n",
    "- Weighted VotingClassifier\n",
    "- StackingClassifier (meta-model)\n",
    "\n",
    "We evaluate using Accuracy, F1, EER, and Confusion Matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "361ce53d",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install xgboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c945e67",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_curve, ConfusionMatrixDisplay\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.ensemble import VotingClassifier, StackingClassifier\n",
    "from xgboost import XGBClassifier\n",
    "sns.set_style('whitegrid')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45c1fe5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_DIR = '/content/drive/My Drive/ProjectLabDataset'\n",
    "TRAIN_FILE = f'{DATA_DIR}/mcytTraining.txt'\n",
    "TEST_FILE = f'{DATA_DIR}/mcytTesting.txt'\n",
    "cols = ['ID', 'SigID', 'X', 'Y', 'P', 'al', 'az', 'signatureOrigin']\n",
    "train_df = pd.read_csv(TRAIN_FILE, names=cols, skiprows=1)\n",
    "test_df = pd.read_csv(TEST_FILE, names=cols, skiprows=1)\n",
    "for df in [train_df, test_df]:\n",
    "    df.columns = df.columns.str.strip()\n",
    "    for col in ['X','Y','P','al','az']:\n",
    "        df[col] = pd.to_numeric(df[col], errors='coerce')\n",
    "train_df['label'] = train_df['signatureOrigin'].map({'Genuine': 1, 'Forged': 0})\n",
    "test_df['label'] = test_df['signatureOrigin'].map({'Genuine': 1, 'Forged': 0})\n",
    "drop_cols = ['ID', 'SigID', 'signatureOrigin', 'al']\n",
    "X_train = train_df.drop(columns=drop_cols + ['label'])\n",
    "y_train = train_df['label']\n",
    "X_test = test_df.drop(columns=drop_cols + ['label'])\n",
    "y_test = test_df['label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77627a32",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bc147dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid_xgb = {\n",
    "    'max_depth': [3, 5],\n",
    "    'learning_rate': [0.05, 0.1],\n",
    "    'n_estimators': [100, 150]\n",
    "}\n",
    "grid_xgb = GridSearchCV(XGBClassifier(use_label_encoder=False, eval_metric='logloss'), param_grid_xgb, scoring='f1', cv=3)\n",
    "grid_xgb.fit(X_train_scaled, y_train)\n",
    "print(\"‚úÖ Best XGBoost Params:\", grid_xgb.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0de8d7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid_mlp = {\n",
    "    'hidden_layer_sizes': [(64,), (64, 32)],\n",
    "    'alpha': [0.0001, 0.001],\n",
    "    'solver': ['adam'],\n",
    "    'max_iter': [500]\n",
    "}\n",
    "grid_mlp = GridSearchCV(MLPClassifier(random_state=42), param_grid_mlp, scoring='f1', cv=3)\n",
    "grid_mlp.fit(X_train_scaled, y_train)\n",
    "print(\"‚úÖ Best MLP Params:\", grid_mlp.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "856b57e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_xgb = grid_xgb.best_estimator_\n",
    "best_mlp = grid_mlp.best_estimator_\n",
    "\n",
    "voting = VotingClassifier(estimators=[('xgb', best_xgb), ('mlp', best_mlp)], voting='soft', weights=[1, 2])\n",
    "voting.fit(X_train_scaled, y_train)\n",
    "y_pred_vote = voting.predict(X_test_scaled)\n",
    "y_prob_vote = voting.predict_proba(X_test_scaled)[:, 1]\n",
    "acc = accuracy_score(y_test, y_pred_vote)\n",
    "f1 = f1_score(y_test, y_pred_vote)\n",
    "print(f'‚úÖ VotingClassifier ‚Äî Accuracy: {acc:.3f}, F1: {f1:.3f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5264752f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_eer(y_true, y_score):\n",
    "    fpr, tpr, thresholds = roc_curve(y_true, y_score)\n",
    "    fnr = 1 - tpr\n",
    "    idx = np.nanargmin(np.abs(fpr - fnr))\n",
    "    eer = (fpr[idx] + fnr[idx]) / 2\n",
    "    return eer, thresholds[idx]\n",
    "\n",
    "eer, threshold = compute_eer(y_test, y_prob_vote)\n",
    "print(f'üîç VotingClassifier EER = {eer:.3f} at threshold = {threshold:.3f}')\n",
    "\n",
    "stack = StackingClassifier(\n",
    "    estimators=[('xgb', best_xgb), ('mlp', best_mlp)],\n",
    "    final_estimator=XGBClassifier(use_label_encoder=False, eval_metric='logloss')\n",
    ")\n",
    "stack.fit(X_train_scaled, y_train)\n",
    "y_pred_stack = stack.predict(X_test_scaled)\n",
    "y_prob_stack = stack.predict_proba(X_test_scaled)[:, 1]\n",
    "acc = accuracy_score(y_test, y_pred_stack)\n",
    "f1 = f1_score(y_test, y_pred_stack)\n",
    "print(f'‚úÖ StackingClassifier ‚Äî Accuracy: {acc:.3f}, F1: {f1:.3f}')\n",
    "ConfusionMatrixDisplay.from_estimator(stack, X_test_scaled, y_test)\n",
    "plt.title(\"Confusion Matrix ‚Äî Stacking Classifier\")\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
